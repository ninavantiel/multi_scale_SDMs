{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>env1_1</th>\n",
       "      <th>env1_10</th>\n",
       "      <th>env1_1_other_n_filter</th>\n",
       "      <th>env1_1_yet_other_n_fliter</th>\n",
       "      <th>env1_1_train_on_val_species</th>\n",
       "      <th>sat25_25</th>\n",
       "      <th>sat25_128</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th>n_occ</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <th>2261</th>\n",
       "      <td>0.822932</td>\n",
       "      <td>0.813024</td>\n",
       "      <td>0.727527</td>\n",
       "      <td>0.861219</td>\n",
       "      <td>0.861264</td>\n",
       "      <td>0.946873</td>\n",
       "      <td>0.886573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>4529</th>\n",
       "      <td>0.558786</td>\n",
       "      <td>0.565781</td>\n",
       "      <td>0.570178</td>\n",
       "      <td>0.553783</td>\n",
       "      <td>0.568638</td>\n",
       "      <td>0.533405</td>\n",
       "      <td>0.570091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>2162</th>\n",
       "      <td>0.926181</td>\n",
       "      <td>0.933392</td>\n",
       "      <td>0.926988</td>\n",
       "      <td>0.918378</td>\n",
       "      <td>0.923759</td>\n",
       "      <td>0.966743</td>\n",
       "      <td>0.961361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <th>4508</th>\n",
       "      <td>0.686647</td>\n",
       "      <td>0.709945</td>\n",
       "      <td>0.696468</td>\n",
       "      <td>0.688919</td>\n",
       "      <td>0.722547</td>\n",
       "      <td>0.695717</td>\n",
       "      <td>0.690877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <th>4539</th>\n",
       "      <td>0.810468</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.846264</td>\n",
       "      <td>0.838688</td>\n",
       "      <td>0.832055</td>\n",
       "      <td>0.655023</td>\n",
       "      <td>0.646752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10028</th>\n",
       "      <th>204</th>\n",
       "      <td>0.946694</td>\n",
       "      <td>0.933916</td>\n",
       "      <td>0.913965</td>\n",
       "      <td>0.883883</td>\n",
       "      <td>0.923963</td>\n",
       "      <td>0.935440</td>\n",
       "      <td>0.954988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10031</th>\n",
       "      <th>20</th>\n",
       "      <td>0.248084</td>\n",
       "      <td>0.480570</td>\n",
       "      <td>0.159473</td>\n",
       "      <td>0.049617</td>\n",
       "      <td>0.727713</td>\n",
       "      <td>0.925239</td>\n",
       "      <td>0.960737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10035</th>\n",
       "      <th>110</th>\n",
       "      <td>0.511612</td>\n",
       "      <td>0.417778</td>\n",
       "      <td>0.434494</td>\n",
       "      <td>0.434544</td>\n",
       "      <td>0.460792</td>\n",
       "      <td>0.356247</td>\n",
       "      <td>0.416178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10038</th>\n",
       "      <th>10</th>\n",
       "      <td>0.985344</td>\n",
       "      <td>0.974049</td>\n",
       "      <td>0.959930</td>\n",
       "      <td>0.980906</td>\n",
       "      <td>0.977679</td>\n",
       "      <td>0.874008</td>\n",
       "      <td>0.849805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10039</th>\n",
       "      <th>2944</th>\n",
       "      <td>0.690419</td>\n",
       "      <td>0.740664</td>\n",
       "      <td>0.663251</td>\n",
       "      <td>0.706555</td>\n",
       "      <td>0.735450</td>\n",
       "      <td>0.688828</td>\n",
       "      <td>0.693995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2174 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 env1_1   env1_10  env1_1_other_n_filter  \\\n",
       "species n_occ                                              \n",
       "1       2261   0.822932  0.813024               0.727527   \n",
       "5       4529   0.558786  0.565781               0.570178   \n",
       "10      2162   0.926181  0.933392               0.926988   \n",
       "11      4508   0.686647  0.709945               0.696468   \n",
       "24      4539   0.810468  0.831081               0.846264   \n",
       "...                 ...       ...                    ...   \n",
       "10028   204    0.946694  0.933916               0.913965   \n",
       "10031   20     0.248084  0.480570               0.159473   \n",
       "10035   110    0.511612  0.417778               0.434494   \n",
       "10038   10     0.985344  0.974049               0.959930   \n",
       "10039   2944   0.690419  0.740664               0.663251   \n",
       "\n",
       "               env1_1_yet_other_n_fliter  env1_1_train_on_val_species  \\\n",
       "species n_occ                                                           \n",
       "1       2261                    0.861219                     0.861264   \n",
       "5       4529                    0.553783                     0.568638   \n",
       "10      2162                    0.918378                     0.923759   \n",
       "11      4508                    0.688919                     0.722547   \n",
       "24      4539                    0.838688                     0.832055   \n",
       "...                                  ...                          ...   \n",
       "10028   204                     0.883883                     0.923963   \n",
       "10031   20                      0.049617                     0.727713   \n",
       "10035   110                     0.434544                     0.460792   \n",
       "10038   10                      0.980906                     0.977679   \n",
       "10039   2944                    0.706555                     0.735450   \n",
       "\n",
       "               sat25_25  sat25_128  \n",
       "species n_occ                       \n",
       "1       2261   0.946873   0.886573  \n",
       "5       4529   0.533405   0.570091  \n",
       "10      2162   0.966743   0.961361  \n",
       "11      4508   0.695717   0.690877  \n",
       "24      4539   0.655023   0.646752  \n",
       "...                 ...        ...  \n",
       "10028   204    0.935440   0.954988  \n",
       "10031   20     0.925239   0.960737  \n",
       "10035   110    0.356247   0.416178  \n",
       "10038   10     0.874008   0.849805  \n",
       "10039   2944   0.688828   0.693995  \n",
       "\n",
       "[2174 rows x 7 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = {\n",
    "    # '0409_env6_3res_1_3_5': '1_3_5',\n",
    "    # '0409_env6_1res_1': '1',\n",
    "    # '0409_env6_1res_3': '3',    \n",
    "    # '0409_env6_1res_5': '5',\n",
    "\n",
    "    # '0405_env16_3res': '1_5_16',\n",
    "    # '0410_env16_1res_1': '1',\n",
    "    # '0410_env16_1res_5': '5',\n",
    "    # '0409_env16_1res': '16',\n",
    "    # '0410_env16_1res_16_v2': '16',\n",
    "    # '0410_env32_1res': '32'\n",
    "\n",
    "    # '0418_env20_1res_1': '1',\n",
    "    # '0419_env20_1res_3': '3',\n",
    "    # '0418_env20_1res_5': '5',\n",
    "    # '0418_env20_1res_10': '10',\n",
    "    # '0418_env20_1res_20': '20',\n",
    "    # '0419_env20_3res_1_3_5': '1_3_5',\n",
    "    # '0422_env20_2res_1_10': '1_10',\n",
    "    # '0422_env20_4res_1_3_5_10': '1_3_5_10',\n",
    "    # '0418_env20_4res': '1_5_10_20',\n",
    "    # '0419_env20_5res': '1_3_5_10_20'\n",
    "\n",
    "    # '0409_env6_1res_1': '1',\n",
    "    # '0416_env6_1res_1_autoencoder': '1_autoencoder',\n",
    "    # '0409_env6_1res_5': '5',\n",
    "    # '0416_env6_1res_5_autoencoder': '5_autoencoder'\n",
    "\n",
    "    # '0425_sat128_1res_resnet_bs1024': '250m',\n",
    "    # '0426_sat128_1res_25': '630m',\n",
    "    # '0426_sat128_1res_52': '1250m',\n",
    "    # '0430_sat18_3res': '3res_bs256!!'\n",
    "\n",
    "    # '0501_sat128_1res_25_bs256': '250m',\n",
    "    # '0501_sat128_1res_63_bs256': '630m',\n",
    "    # '0501_sat128_1res_125_bs256': '1250m',\n",
    "    # '0501_sat128_3res_2174_bs256': '3res'\n",
    "\n",
    "    # '0510_env3res': 'env_3res',\n",
    "    # '0510_sat3res': 'sat_3res',\n",
    "    # '0510_multimodel_multires': 'env_3res_sat_3res'\n",
    "\n",
    "    '0604_env1_1': 'env1_1',\n",
    "    '0604_env1_10': 'env1_10',\n",
    "    '0604_env1_1_other_n_filters': 'env1_1_other_n_filter',\n",
    "    '0605_env1_1_yet_other_n_filters': 'env1_1_yet_other_n_fliter',\n",
    "    '0605_env1_1_train_set_only_val_species': 'env1_1_train_on_val_species',\n",
    "    '0604_sat25_25': 'sat25_25',\n",
    "    '0604_sat25_128': 'sat25_128'\n",
    "}\n",
    "checkpoint = 'last' #'best_val_auc' # \n",
    "auc_df = pd.concat([\n",
    "    pd.read_csv(f\"models/{k}/{checkpoint}_species_auc.csv\").rename(columns={\"auc\": v}).set_index(['species','n_occ']) for k, v in models.items()\n",
    "], axis=1)\n",
    "\n",
    "auc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/GLC23/Presence_Absence_surveys/Presences_Absences_train.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "speciesId\n",
       "1          3\n",
       "5         14\n",
       "10         5\n",
       "11        20\n",
       "24       588\n",
       "        ... \n",
       "10028      3\n",
       "10031      1\n",
       "10035     16\n",
       "10038      1\n",
       "10039     48\n",
       "Name: patchID, Length: 2174, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pa_path = get_path_to(\"pa\", \"glc23\", datadir)\n",
    "print(pa_path)\n",
    "n_occ_val = pd.read_csv(pa_path, sep=\";\", header='infer', low_memory=False).groupby('speciesId')['patchID'].count() # GLC23\n",
    "# n_occ_val = pd.read_csv(pa_path, sep=\",\", header='infer', low_memory=False).groupby('speciesId')['surveyId'].count() # GLC24\n",
    "n_occ_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>n_occ</th>\n",
       "      <th>env1_1</th>\n",
       "      <th>env1_10</th>\n",
       "      <th>env1_1_other_n_filter</th>\n",
       "      <th>env1_1_yet_other_n_fliter</th>\n",
       "      <th>env1_1_train_on_val_species</th>\n",
       "      <th>sat25_25</th>\n",
       "      <th>sat25_128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>4529</td>\n",
       "      <td>0.558786</td>\n",
       "      <td>0.565781</td>\n",
       "      <td>0.570178</td>\n",
       "      <td>0.553783</td>\n",
       "      <td>0.568638</td>\n",
       "      <td>0.533405</td>\n",
       "      <td>0.570091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>2162</td>\n",
       "      <td>0.926181</td>\n",
       "      <td>0.933392</td>\n",
       "      <td>0.926988</td>\n",
       "      <td>0.918378</td>\n",
       "      <td>0.923759</td>\n",
       "      <td>0.966743</td>\n",
       "      <td>0.961361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>4508</td>\n",
       "      <td>0.686647</td>\n",
       "      <td>0.709945</td>\n",
       "      <td>0.696468</td>\n",
       "      <td>0.688919</td>\n",
       "      <td>0.722547</td>\n",
       "      <td>0.695717</td>\n",
       "      <td>0.690877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>4539</td>\n",
       "      <td>0.810468</td>\n",
       "      <td>0.831081</td>\n",
       "      <td>0.846264</td>\n",
       "      <td>0.838688</td>\n",
       "      <td>0.832055</td>\n",
       "      <td>0.655023</td>\n",
       "      <td>0.646752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>1305</td>\n",
       "      <td>0.995829</td>\n",
       "      <td>0.990609</td>\n",
       "      <td>0.995749</td>\n",
       "      <td>0.993758</td>\n",
       "      <td>0.996906</td>\n",
       "      <td>0.774304</td>\n",
       "      <td>0.806000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2162</th>\n",
       "      <td>10002</td>\n",
       "      <td>45</td>\n",
       "      <td>0.945460</td>\n",
       "      <td>0.944018</td>\n",
       "      <td>0.929927</td>\n",
       "      <td>0.926793</td>\n",
       "      <td>0.936982</td>\n",
       "      <td>0.925496</td>\n",
       "      <td>0.866572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2166</th>\n",
       "      <td>10023</td>\n",
       "      <td>998</td>\n",
       "      <td>0.889197</td>\n",
       "      <td>0.876120</td>\n",
       "      <td>0.832934</td>\n",
       "      <td>0.847895</td>\n",
       "      <td>0.827257</td>\n",
       "      <td>0.772286</td>\n",
       "      <td>0.749173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2168</th>\n",
       "      <td>10025</td>\n",
       "      <td>620</td>\n",
       "      <td>0.545841</td>\n",
       "      <td>0.276256</td>\n",
       "      <td>0.407251</td>\n",
       "      <td>0.429379</td>\n",
       "      <td>0.441663</td>\n",
       "      <td>0.481708</td>\n",
       "      <td>0.377819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>10035</td>\n",
       "      <td>110</td>\n",
       "      <td>0.511612</td>\n",
       "      <td>0.417778</td>\n",
       "      <td>0.434494</td>\n",
       "      <td>0.434544</td>\n",
       "      <td>0.460792</td>\n",
       "      <td>0.356247</td>\n",
       "      <td>0.416178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2173</th>\n",
       "      <td>10039</td>\n",
       "      <td>2944</td>\n",
       "      <td>0.690419</td>\n",
       "      <td>0.740664</td>\n",
       "      <td>0.663251</td>\n",
       "      <td>0.706555</td>\n",
       "      <td>0.735450</td>\n",
       "      <td>0.688828</td>\n",
       "      <td>0.693995</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1331 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      species  n_occ    env1_1   env1_10  env1_1_other_n_filter  \\\n",
       "1           5   4529  0.558786  0.565781               0.570178   \n",
       "2          10   2162  0.926181  0.933392               0.926988   \n",
       "3          11   4508  0.686647  0.709945               0.696468   \n",
       "4          24   4539  0.810468  0.831081               0.846264   \n",
       "6          33   1305  0.995829  0.990609               0.995749   \n",
       "...       ...    ...       ...       ...                    ...   \n",
       "2162    10002     45  0.945460  0.944018               0.929927   \n",
       "2166    10023    998  0.889197  0.876120               0.832934   \n",
       "2168    10025    620  0.545841  0.276256               0.407251   \n",
       "2171    10035    110  0.511612  0.417778               0.434494   \n",
       "2173    10039   2944  0.690419  0.740664               0.663251   \n",
       "\n",
       "      env1_1_yet_other_n_fliter  env1_1_train_on_val_species  sat25_25  \\\n",
       "1                      0.553783                     0.568638  0.533405   \n",
       "2                      0.918378                     0.923759  0.966743   \n",
       "3                      0.688919                     0.722547  0.695717   \n",
       "4                      0.838688                     0.832055  0.655023   \n",
       "6                      0.993758                     0.996906  0.774304   \n",
       "...                         ...                          ...       ...   \n",
       "2162                   0.926793                     0.936982  0.925496   \n",
       "2166                   0.847895                     0.827257  0.772286   \n",
       "2168                   0.429379                     0.441663  0.481708   \n",
       "2171                   0.434544                     0.460792  0.356247   \n",
       "2173                   0.706555                     0.735450  0.688828   \n",
       "\n",
       "      sat25_128  \n",
       "1      0.570091  \n",
       "2      0.961361  \n",
       "3      0.690877  \n",
       "4      0.646752  \n",
       "6      0.806000  \n",
       "...         ...  \n",
       "2162   0.866572  \n",
       "2166   0.749173  \n",
       "2168   0.377819  \n",
       "2171   0.416178  \n",
       "2173   0.693995  \n",
       "\n",
       "[1331 rows x 9 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_df_n_val_gte_5 = auc_df.reset_index()[auc_df.reset_index()['species'].isin(n_occ_val[n_occ_val >= 5].index)]\n",
    "auc_df_n_val_gte_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0604_env1_1 17 0.8718434343434344\n",
      "0604_env1_10 21 0.8718093699515347\n",
      "0604_env1_1_other_n_filters 10 0.8738675098672407\n",
      "0605_env1_1_yet_other_n_filters 14 0.8747468268971105\n",
      "0605_env1_1_train_set_only_val_species 27 0.8838032808809329\n",
      "0604_sat25_25 24 0.8025147928994083\n",
      "0604_sat25_128 27 0.7953475863923625\n"
     ]
    }
   ],
   "source": [
    "for run_name in models.keys():\n",
    "        checkpoint = torch.load(f\"{modeldir}{run_name}/best_val_auc.pth\")\n",
    "        epoch = checkpoint['epoch'] \n",
    "        auc = checkpoint['val_auc']\n",
    "        print(run_name, epoch, auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "env1_1                         0.868028\n",
       "env1_10                        0.861908\n",
       "env1_1_other_n_filter          0.863508\n",
       "env1_1_yet_other_n_fliter      0.863879\n",
       "env1_1_train_on_val_species    0.879925\n",
       "sat25_25                       0.788322\n",
       "sat25_128                      0.792421\n",
       "dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species    5154.000000\n",
       "n_occ      1513.000000\n",
       "25_25         0.769393\n",
       "25_128        0.769144\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_df_n_val_gte_5.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25_25     0.747929\n",
       "25_128    0.751954\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species    5110.099925\n",
       "n_occ      2129.128475\n",
       "25_25         0.745161\n",
       "25_128        0.746923\n",
       "dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_df_n_val_gte_5.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = '0527_glc24_env_1_val_france'\n",
    "path_to_config = f\"{modeldir}{run_name}/config.json\"\n",
    "with open(path_to_config, \"r\") as f: \n",
    "    config = json.load(f)\n",
    "config = {k: v if v != \"\" else None for k,v in config.items()}\n",
    "\n",
    "log_wandb = config['log_wandb']\n",
    "wandb_project = config['wandb_project']\n",
    "wandb_id = config['wandb_id']\n",
    "env_model = config['env_model']\n",
    "sat_model = config['sat_model']\n",
    "dataset = config['dataset']\n",
    "random_bg = config['random_bg']\n",
    "n_max_low_occ = config['n_max_low_occ']\n",
    "embed_shape = config['embed_shape']\n",
    "loss = config['loss']\n",
    "lambda2 = config['lambda2']\n",
    "n_epochs = config['n_epochs']\n",
    "batch_size = config['batch_size']\n",
    "learning_rate = config['learning_rate']\n",
    "weight_decay = config['weight_decay']\n",
    "num_workers_train = config['num_workers_train']\n",
    "num_workers_val = config['num_workers_val']\n",
    "seed = config['seed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: cuda\n",
      "\n",
      "Making patch providers with size=10x10, flatten=False for covariates:\n",
      "\t - data/GLC24/EnvironmentalRasters/Climate/BioClimatic_Average_1981-2010/\n",
      "\t - data/GLC24/EnvironmentalRasters/Soilgrids/\n",
      "\t - data/GLC24/EnvironmentalRasters/LandCover/LandCover_MODIS_Terra-Aqua_500m.tif\n",
      "\n",
      "Making patch providers with size=10x10, flatten=False for covariates:\n",
      "\t - data/GLC24/EnvironmentalRasters/Climate/BioClimatic_Average_1981-2010/\n",
      "\t - data/GLC24/EnvironmentalRasters/Soilgrids/\n",
      "\t - data/GLC24/EnvironmentalRasters/LandCover/LandCover_MODIS_Terra-Aqua_500m.tif\n",
      "\n",
      "Making dataset for training occurrences\n",
      "nb items = 3894962\n",
      "input shape: [(41, 10, 10)]\n",
      "\n",
      "Making dataset for validation occurrences\n",
      "nb items = 88987\n",
      "\n",
      "Making model\n"
     ]
    }
   ],
   "source": [
    "seed_everything(seed)\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"DEVICE: {dev}\")\n",
    "\n",
    "train_data, val_data, model, optimizer, multimodal, autoencoder = setup_model(\n",
    "    env_model=env_model,\n",
    "    sat_model=sat_model,\n",
    "    dataset=dataset,\n",
    "    random_bg=random_bg,\n",
    "    n_max_low_occ=n_max_low_occ,\n",
    "    embed_shape=embed_shape, \n",
    "    learning_rate=learning_rate, \n",
    "    weight_decay=weight_decay,\n",
    "    seed=seed) \n",
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=batch_size, num_workers=num_workers_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(f\"{modeldir}{run_name}/last.pth\")\n",
    "start_epoch = checkpoint['epoch'] + 1\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 348/348 [00:10<00:00, 33.86it/s]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "labels_list, y_pred_list = [], []\n",
    "for inputs, _, labels in tqdm(val_loader):\n",
    "    labels = labels.to(torch.float32).to(dev) \n",
    "    labels_list.append(labels.cpu().detach().numpy())\n",
    "\n",
    "    inputs = inputs[0].to(torch.float32).to(dev)\n",
    "    y_pred = torch.sigmoid(model(inputs))\n",
    "\n",
    "    y_pred_list.append(y_pred.cpu().detach().numpy())\n",
    "      \n",
    "labels = np.concatenate(labels_list)\n",
    "y_pred = np.concatenate(y_pred_list)\n",
    "\n",
    "# validation AUC\n",
    "\n",
    "# auc = roc_auc_score(labels, y_pred)\n",
    "# print(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = labels[:, val_data.species_pred_in_data]\n",
    "y_pred = y_pred[:, val_data.species_pred_in_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88987, 4367) (88987, 4367)\n"
     ]
    }
   ],
   "source": [
    "print(labels.shape, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torcheval.metrics.functional import binary_auroc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4367, 88987]) torch.Size([4367, 88987])\n"
     ]
    }
   ],
   "source": [
    "pred_torch = torch.from_numpy(y_pred.T)\n",
    "labels_torch = torch.from_numpy(labels.T)\n",
    "print(pred_torch.shape, labels_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4367"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_torch.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.8514, dtype=torch.float64)\n",
      "9.726004838943481\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "auc = binary_auroc(pred_torch, labels_torch, num_tasks=4367)\n",
    "end = time.time()\n",
    "print(auc.mean())\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9502361038433524"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc.median().item()#cpu().detach().number()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8317704038395496\n",
      "20.06242036819458\n"
     ]
    }
   ],
   "source": [
    "labels_filter = labels[:, :100]\n",
    "y_pred_filter = y_pred[:, :100]\n",
    "start = time.time()\n",
    "auc = roc_auc_score(labels_filter, y_pred_filter)\n",
    "end = time.time()\n",
    "print(auc)\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_810942/820455611.py:1: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  auc_df.reset_index()[auc_df.reset_index()['species'].isin(n_occ_val[n_occ_val >= 5].index)][auc_df.reset_index()['n_occ'] <= 50].mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "species              4883.902062\n",
       "n_occ                  16.329897\n",
       "env_3res                0.773105\n",
       "sat_3res                0.788907\n",
       "env_3res_sat_3res       0.859192\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_df.reset_index()[auc_df.reset_index()['species'].isin(n_occ_val[n_occ_val >= 5].index)][auc_df.reset_index()['n_occ'] <= 50].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = '0527_glc24_env_1'\n",
    "path_to_config = modeldir + run_name + '/config.json'\n",
    "with open(path_to_config, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config = {k: v if v != \"\" else None for k,v in config.items()}\n",
    "log_wandb = config['log_wandb']\n",
    "wandb_project = config['wandb_project']\n",
    "wandb_id = config['wandb_id']\n",
    "env_model = config['env_model']\n",
    "sat_model = config['sat_model']\n",
    "dataset = config['dataset']\n",
    "random_bg = config['random_bg']\n",
    "n_max_low_occ = config['n_max_low_occ']\n",
    "embed_shape = config['embed_shape']\n",
    "loss = config['loss']\n",
    "lambda2 = config['lambda2']\n",
    "n_epochs = config['n_epochs']\n",
    "batch_size = config['batch_size']\n",
    "learning_rate = config['learning_rate']\n",
    "weight_decay = config['weight_decay']\n",
    "num_workers_train = config['num_workers_train']\n",
    "num_workers_val = config['num_workers_val']\n",
    "seed = config['seed']\n",
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making patch providers with size=10x10, flatten=False for covariates:\n",
      "\t - data/glc24_data/EnvironmentalRasters/Climate/BioClimatic_Average_1981-2010/\n",
      "\t - data/glc24_data/EnvironmentalRasters/Soilgrids/\n",
      "\t - data/glc24_data/EnvironmentalRasters/LandCover/LandCover_MODIS_Terra-Aqua_500m.tif\n",
      "\n",
      "Making patch providers with size=10x10, flatten=False for covariates:\n",
      "\t - data/glc24_data/EnvironmentalRasters/Climate/BioClimatic_Average_1981-2010/\n",
      "\t - data/glc24_data/EnvironmentalRasters/Soilgrids/\n",
      "\t - data/glc24_data/EnvironmentalRasters/LandCover/LandCover_MODIS_Terra-Aqua_500m.tif\n",
      "\n",
      "Making dataset for training occurrences\n",
      "nb items = 3894962\n",
      "nb species = 9709\n",
      "input shape: [(41, 10, 10)]\n",
      "\n",
      "Making dataset for validation occurrences\n",
      "nb items = 88987\n",
      "nb species = 9709\n",
      "\n",
      "Making model\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'dev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m train_data, val_data, model, optimizer, multimodal, autoencoder \u001b[38;5;241m=\u001b[39m setup_model(\n\u001b[1;32m      2\u001b[0m     env_model\u001b[38;5;241m=\u001b[39menv_model,\n\u001b[1;32m      3\u001b[0m     sat_model\u001b[38;5;241m=\u001b[39msat_model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     weight_decay\u001b[38;5;241m=\u001b[39mweight_decay,\n\u001b[1;32m     10\u001b[0m     seed\u001b[38;5;241m=\u001b[39mseed) \n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(\u001b[43mdev\u001b[49m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dev' is not defined"
     ]
    }
   ],
   "source": [
    "train_data, val_data, model, optimizer, multimodal, autoencoder = setup_model(\n",
    "    env_model=env_model,\n",
    "    sat_model=sat_model,\n",
    "    dataset=dataset,\n",
    "    random_bg=random_bg,\n",
    "    n_max_low_occ=n_max_low_occ,\n",
    "    embed_shape=embed_shape, \n",
    "    learning_rate=learning_rate, \n",
    "    weight_decay=weight_decay,\n",
    "    seed=seed) \n",
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=batch_size, num_workers=num_workers_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 348/348 [00:08<00:00, 42.28it/s]\n"
     ]
    }
   ],
   "source": [
    "labels_list = []\n",
    "for inputs, _, labels in tqdm(val_loader):\n",
    "    labels = labels.to(torch.float32).to(dev) \n",
    "    labels_list.append(labels.cpu().detach().numpy())\n",
    "labels = np.concatenate(labels_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88987, 9709)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9709,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.sum(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5342"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(labels.sum(axis=0) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_to_select = [s in val_data.species_counts.index for s in val_data.species]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(88987, 4367)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:,species_to_select].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(labels[:,species_to_select].sum(axis=0) == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0         67\n",
       "1.0          1\n",
       "2.0        248\n",
       "4.0          1\n",
       "5.0         42\n",
       "          ... \n",
       "11248.0     12\n",
       "11250.0     13\n",
       "11252.0     12\n",
       "11253.0     23\n",
       "11254.0      4\n",
       "Length: 9709, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.species_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = eval(loss)\n",
    "species_weights = torch.tensor(train_data.species_weights).to(dev)\n",
    "val_loss_fn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 0.8193423272756075\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load(f\"{modeldir}{run_name}/best_val_auc.pth\")\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch'] + 1\n",
    "max_val_auc = checkpoint['val_auc']\n",
    "print(epoch, max_val_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 23.69 GiB total capacity; 22.79 GiB already allocated; 275.94 MiB free; 23.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     inputsA \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(dev)\n\u001b[1;32m     10\u001b[0m     inputsB \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(dev)\n\u001b[0;32m---> 11\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputsA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputsB\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     13\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m inputs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mfloat32)\u001b[38;5;241m.\u001b[39mto(dev)\n",
      "File \u001b[0;32m~/miniconda3/envs/glc23/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GeoLifeCLEF/models.py:116\u001b[0m, in \u001b[0;36mMultimodalModel.forward\u001b[0;34m(self, x1, x2)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x1, x2):\n\u001b[1;32m    115\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodelA(x1)\n\u001b[0;32m--> 116\u001b[0m     x2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodelB\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((x1, x2), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    118\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/glc23/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GeoLifeCLEF/models.py:259\u001b[0m, in \u001b[0;36mMultiResolutionModel.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m--> 259\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     xlist \u001b[38;5;241m=\u001b[39m [aspp(x) \u001b[38;5;28;01mfor\u001b[39;00m aspp \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maspp_branches]\n\u001b[1;32m    261\u001b[0m     x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(xlist, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/glc23/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GeoLifeCLEF/models.py:234\u001b[0m, in \u001b[0;36mResNet_3layers.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m    233\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer0(x)\n\u001b[0;32m--> 234\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer2(x)\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/glc23/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/glc23/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/glc23/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/glc23/lib/python3.9/site-packages/torchvision/models/resnet.py:97\u001b[0m, in \u001b[0;36mBasicBlock.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     94\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n\u001b[1;32m     96\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(out)\n\u001b[0;32m---> 97\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbn2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    100\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/glc23/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/glc23/lib/python3.9/site-packages/torch/nn/modules/batchnorm.py:171\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    164\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    166\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    181\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    183\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/glc23/lib/python3.9/site-packages/torch/nn/functional.py:2450\u001b[0m, in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[1;32m   2448\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[0;32m-> 2450\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2451\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\n\u001b[1;32m   2452\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1024.00 MiB (GPU 0; 23.69 GiB total capacity; 22.79 GiB already allocated; 275.94 MiB free; 23.02 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# evaluate model on validation set\n",
    "model.eval()\n",
    "val_loss_list, val_classif_loss_list, val_reconstr_loss_list, labels_list, y_pred_list = [], [], [], [], []\n",
    "for inputs, _, labels in tqdm(val_loader):\n",
    "    labels = labels.to(torch.float32).to(dev) \n",
    "    labels_list.append(labels.cpu().detach().numpy())\n",
    "\n",
    "    if multimodal:\n",
    "        inputsA = inputs[0].to(torch.float32).to(dev)\n",
    "        inputsB = inputs[1].to(torch.float32).to(dev)\n",
    "        y_pred = torch.sigmoid(model(inputsA, inputsB))\n",
    "    else:\n",
    "        inputs = inputs[0].to(torch.float32).to(dev)\n",
    "        y_pred = torch.sigmoid(model(inputs))\n",
    "\n",
    "    y_pred_list.append(y_pred.cpu().detach().numpy())\n",
    "\n",
    "labels = np.concatenate(labels_list)\n",
    "y_pred = np.concatenate(y_pred_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f\"{modeldir}{run_name}/y_pred_best_val_auc.pth\", y_pred)\n",
    "np.save(f\"{modeldir}{run_name}/y_true.pth\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        # validation AUC\n",
    "        auc = roc_auc_score(labels, y_pred)\n",
    "        auc_low_occ = roc_auc_score(labels[:, train_data.low_occ_species_idx], y_pred[:, train_data.low_occ_species_idx])\n",
    "\n",
    "        # if autoencoder:\n",
    "        #     avg_val_classif_loss = np.mean(val_classif_loss_list)\n",
    "        #     avg_val_reconstr_loss = np.mean(val_reconstr_loss_list, axis=0)\n",
    "        #     print(f\"\\tVALIDATION LOSS={avg_val_loss} (classification loss={avg_val_classif_loss}, reconstruction loss={avg_val_reconstr_loss}) \\nVALIDATION AUC={auc}\")\n",
    "        # else:\n",
    "        print(f\"\\tVALIDATION LOSS={avg_val_loss} \\nVALIDATION AUC={auc}\")\n",
    "\n",
    "        df = pd.DataFrame(train_data.species_counts, columns=['n_occ']).reset_index().rename(columns={'index':'species'})\n",
    "        df['auc'] = [roc_auc_score(labels[:,i], y_pred[:,i]) for i in range(labels.shape[1])]\n",
    "        df.to_csv(f\"{modeldir}{run_name}/last_species_auc.csv\", index=False)\n",
    "\n",
    "        if log_wandb:\n",
    "            wandb.log({\"train_loss\": avg_train_loss, \"val_loss\": avg_val_loss, \"val_auc\": auc, \"val_auc_low_occ\": auc_low_occ})\n",
    "            # if autoencoder:\n",
    "            #     wandb.log({\"train_total_loss\": avg_train_loss, \"val_total_loss\": avg_val_loss})\n",
    "            #     if len(avg_train_reconstr_loss) == 1:\n",
    "            #         wandb.log({\"train_reconstr_loss_1\": avg_train_reconstr_loss[0], \"val_reconstr_loss_1\": avg_val_reconstr_loss[0]})\n",
    "            #     elif len(avg_train_reconstr_loss) == 3:\n",
    "            #         wandb.log({\n",
    "            #             \"train_reconstr_loss_1\": avg_train_reconstr_loss[0], \"train_reconstr_loss_2\": avg_train_reconstr_loss[1], \"train_reconstr_loss_3\": avg_train_reconstr_loss[2],\n",
    "            #             \"val_reconstr_loss_1\": avg_val_reconstr_loss[0], \"val_reconstr_loss_2\": avg_val_reconstr_loss[1], \"val_reconstr_loss_3\": avg_val_reconstr_loss[2]\n",
    "            #         })\n",
    "            #     else:\n",
    "            #         print('cannot log reconstruction losses!')\n",
    "\n",
    "        # model checkpoint\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'train_loss': avg_train_loss,\n",
    "            'val_loss': avg_val_loss,\n",
    "            'val_auc': auc\n",
    "        }, f\"{modeldir}/{run_name}/last.pth\") \n",
    "\n",
    "        # save best model\n",
    "        if auc > max_val_auc:\n",
    "            max_val_auc = auc\n",
    "            df.to_csv(f\"{modeldir}{run_name}/best_val_auc_species_auc.csv\", index=False)\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'train_loss': avg_train_loss,\n",
    "                'val_loss': avg_val_loss,\n",
    "                'val_auc': auc\n",
    "            }, f\"{modeldir}{run_name}/best_val_auc.pth\")  \n",
    "\n",
    "    \n",
    "\n",
    "# run_name = '0510_multimodel_multires'\n",
    "# path_to_config = f\"{modeldir}{run_name}/config.json\"\n",
    "# with open(path_to_config, \"r\") as f: \n",
    "#     config = json.load(f)\n",
    "# config = {k: v if v != \"\" else None for k,v in config.items()}\n",
    "# model_setup = {}\n",
    "\n",
    "# if config['env_model'] is not None: \n",
    "#     config['env_model']['covariates'] = [eval(f) for f in config['env_model']['covariates']]\n",
    "#     model_setup['env'] = config['env_model']\n",
    "\n",
    "# if config['sat_model'] is not None: \n",
    "#     config['sat_model']['covariates'] = [eval(f) for f in config['sat_model']['covariates']]\n",
    "#     model_setup['sat'] = config['sat_model']\n",
    "\n",
    "# train_occ_path = eval(config['train_occ_path'])\n",
    "# random_bg_path = eval(config['random_bg_path']) if config['random_bg_path'] is not None else None\n",
    "# val_occ_path = eval(config['val_occ_path'])\n",
    "# n_max_low_occ = config['n_max_low_occ']\n",
    "# embed_shape = config['embed_shape']\n",
    "# loss = config['loss']\n",
    "# lambda2 = config['lambda2']\n",
    "# n_epochs = config['n_epochs']\n",
    "# batch_size = config['batch_size']\n",
    "# learning_rate = config['learning_rate']\n",
    "# weight_decay = config['weight_decay']\n",
    "# num_workers_train = config['num_workers_train']\n",
    "# num_workers_val = config['num_workers_val']\n",
    "# seed = config['seed']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glc23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
