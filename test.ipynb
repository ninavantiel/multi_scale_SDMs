{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_config = 'models/0308_env_aspp_mlp_backbone/config.json'\n",
    "with open(path_to_config, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config = {k: v if v != \"\" else None for k,v in config.items()}\n",
    "model_setup = {}\n",
    "if config['env_model'] is not None: \n",
    "    config['env_model']['covariates'] = [eval(f) for f in config['env_model']['covariates']]\n",
    "    model_setup['env'] = config['env_model']\n",
    "if config['sat_model'] is not None: \n",
    "    config['sat_model']['covariates'] = [eval(f) for f in config['sat_model']['covariates']]\n",
    "    model_setup['sat'] = config['sat_model']\n",
    "train_occ_path = eval(config['train_occ_path'])\n",
    "random_bg_path = eval(config['random_bg_path']) if config['random_bg_path'] is not None else None\n",
    "val_occ_path = eval(config['val_occ_path'])\n",
    "n_max_low_occ = config['n_max_low_occ']\n",
    "embed_shape = config['embed_shape']\n",
    "loss = config['loss']\n",
    "lambda2 = config['lambda2']\n",
    "batch_size = config['batch_size']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Making patch providers with size=1x1, flatten=False for covariates:\n",
      "\t - data/full_data/EnvironmentalRasters/Climate/BioClimatic_Average_1981-2010/\n",
      "\t - data/full_data/EnvironmentalRasters/Soilgrids/\n",
      "\t - data/full_data/EnvironmentalRasters/LandCover/LandCover_MODIS_Terra-Aqua_500m.tif\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_dict \u001b[38;5;129;01min\u001b[39;00m model_setup\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[1;32m      3\u001b[0m     flatten \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m model_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMLP\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \n\u001b[0;32m----> 4\u001b[0m     providers\u001b[38;5;241m.\u001b[39mappend(\u001b[43mmake_providers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcovariates\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpatch_size\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Documents/GeoLifeCLEF/train_model.py:42\u001b[0m, in \u001b[0;36mmake_providers\u001b[0;34m(covariate_paths_list, patch_size, flatten)\u001b[0m\n\u001b[1;32m     40\u001b[0m     providers\u001b[38;5;241m.\u001b[39mappend(JpegPatchProvider(cov, size\u001b[38;5;241m=\u001b[39mpatch_size))\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.tif\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m cov:\n\u001b[0;32m---> 42\u001b[0m     providers\u001b[38;5;241m.\u001b[39mappend(\u001b[43mRasterPatchProvider\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflatten\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m     providers\u001b[38;5;241m.\u001b[39mappend(MultipleRasterPatchProvider(cov, size\u001b[38;5;241m=\u001b[39mpatch_size, flatten\u001b[38;5;241m=\u001b[39mflatten))\n",
      "File \u001b[0;32m~/Documents/GeoLifeCLEF/data/PatchesProviders.py:93\u001b[0m, in \u001b[0;36mRasterPatchProvider.__init__\u001b[0;34m(self, raster_path, size, flatten, normalize, fill_zero_if_error, nan_value)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# iterate through all the layers\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(src\u001b[38;5;241m.\u001b[39mcount):\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;66;03m# replace the NoData values with np.nan\u001b[39;00m\n\u001b[0;32m---> 93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSoilgrids\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraster_path:\n\u001b[1;32m     95\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39misclose(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[i], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnodata_value[i]), np\u001b[38;5;241m.\u001b[39mnan, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata[i])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "providers = []\n",
    "for model_dict in model_setup.values():\n",
    "    flatten = True if model_dict['model_name'] == 'MLP' else False \n",
    "    providers.append(make_providers(\n",
    "        model_dict['covariates'], model_dict['patch_size'], flatten\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PatchesDatasetCooccurrences(\n",
    "    occurrences=train_occ_path, \n",
    "    providers=providers, \n",
    "    pseudoabsences=random_bg_path, \n",
    "    n_low_occ=n_max_low_occ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_setup = {}\n",
    "if dict['env_model'] is not None: model_setup['env'] = config['env_model']\n",
    "if dict['sat_model'] is not None: model_setup['sat'] = config['sat_model']\n",
    "model_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[eval(f) for f in config['env_model']['covariates']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config['e_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_occ_path=po_path_sampled_25\n",
    "random_bg_path=None\n",
    "val_occ_path=pa_path\n",
    "env_model={'model_name':'ASPP', 'covariates':[bioclim_dir, soil_dir, landcover_path], 'patch_size': 10, 'embed_shape': 64, 'kernel_sizes': [1,3,3], 'dilations': [1,1,2]}\n",
    "sat_model=None\n",
    "n_max_low_occ=50\n",
    "embed_shape=None\n",
    "loss='an_full_loss'\n",
    "lambda2=None\n",
    "n_epochs=100\n",
    "batch_size=128\n",
    "learning_rate=1e-3\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_setup = {}\n",
    "if env_model is not None: model_setup['env'] = env_model\n",
    "if sat_model is not None: model_setup['sat'] = sat_model\n",
    "print(model_setup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"DEVICE: {dev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, model, optimizer, multires = setup_model(\n",
    "    model_setup, train_occ_path, random_bg_path, val_occ_path, n_max_low_occ,\n",
    "    embed_shape, learning_rate, seed)\n",
    "model = model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=10\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=batch_size)#, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = eval(loss)\n",
    "species_weights = torch.tensor(train_data.species_weights).to(dev)\n",
    "val_loss_fn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for po_inputs, bg_inputs, labels in tqdm(train_loader):\n",
    "   labels = labels.to(torch.float32).to(dev)\n",
    "   inputs = po_inputs[0].to(torch.float32).to(dev)\n",
    "   break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = torch.sigmoid(model(inputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = inputs\n",
    "x_in = [x[:, :, imin:imax, imin:imax] for imin, imax in zip(model.imins, model.imaxs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = model.aspp_branches[0].to(dev)\n",
    "m(x_in[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = [aspp(xi) for aspp, xi in zip(model.aspp_branches, x_in)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([xi.get_device() for xi in x_in])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.subpatch_sizes)\n",
    "print(model.center_idx)\n",
    "print(model.imins)\n",
    "print(model.imaxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.center_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i >= 0 for i in imins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(np.array(imaxs) < 4).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    y_pred = torch.sigmoid(model(inputs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "def aspp_branch(in_channels, out_channels, kernel_size, dilation):\n",
    "    '''\n",
    "    As implemented in:\n",
    "    https://github.com/yassouali/pytorch-segmentation/blob/master/models/deeplabv3_plus.py\n",
    "    '''\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels, out_channels, kernel_size,dilation=dilation),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes = [1, 3, 3, 3]\n",
    "dilations = [1, 1, 2, 3]\n",
    "subpatch_sizes = [(d-1)*(k-1) + k for k, d in zip(kernel_sizes, dilations)]\n",
    "print(subpatch_sizes)\n",
    "in_patch_size = 8\n",
    "center_idx = in_patch_size // 2\n",
    "print(center_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 41\n",
    "out_channels = 64\n",
    "aspp_branches = [aspp_branch(in_channels, out_channels, k, d) for k, d in zip(kernel_sizes, dilations)]\n",
    "len(aspp_branches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = po_inputs[0].to(torch.float32)\n",
    "imins = [int(center_idx - (s-1)/2) for s in subpatch_sizes]\n",
    "imaxs = [int(center_idx + (s-1)/2 + 1) for s in subpatch_sizes]\n",
    "x_in = [x[:, :, imin:imax, imin:imax] for imin, imax in zip(imins, imaxs)]\n",
    "x_out = [aspp(xi) for aspp, xi in zip(aspp_branches, x_in)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([o.shape for o in x_out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.cat(x_out, dim=1).squeeze()\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = nn.Linear(256, 10)\n",
    "l(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel_sizes = [1, 3, 3, 3]\n",
    "dilations = [1, 1, 2, 3]\n",
    "subpatch_sizes = [(d-1)*(k-1) + k for k, d in zip(kernel_sizes, dilations)]\n",
    "print(subpatch_sizes)\n",
    "in_patch_size = 9\n",
    "center_idx = in_patch_size // 2\n",
    "print(center_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imins = [int(center_idx - (s-1)/2) for s in subpatch_sizes]\n",
    "imaxs = [int(center_idx + (s-1)/2 + 1) for s in subpatch_sizes]\n",
    "x_in = [x[:, imin:imax, imin:imax] for imin, imax in zip(imins, imaxs)]\n",
    "print([y.shape for y in x_in])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels = 41\n",
    "out_channels = 128\n",
    "aspp_branches = [aspp_branch(in_channels, out_channels, k, d) for k, d in zip(kernel_sizes, dilations)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xi = x_in[0].to(torch.double)\n",
    "aspp = aspp_branches[0]\n",
    "print(xi.shape)\n",
    "print(aspp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "pdb.set_trace()\n",
    "aspp(xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_out = [torch.rand((out_channels, 1, 1)) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cat(x_out, dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = train_data.items.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{p.n_rows} - ({item.lat} - {p.y_min}) / {p.y_resolution})\")\n",
    "print(p.n_rows - (item.lat - p.y_min) / p.y_resolution)\n",
    "x = int(p.n_rows - (item.lat - p.y_min) / p.y_resolution)\n",
    "y = int((item.lon - p.x_min) / p.x_resolution)\n",
    "print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{x} - ({p.patch_size} // 2), {x} + ({p.patch_size} // 2)\")\n",
    "print(x - (p.patch_size // 2), x + (p.patch_size // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{y} - ({p.patch_size} // 2), {y} + ({p.patch_size} // 2)\")\n",
    "print(y - (p.patch_size // 2), y + (p.patch_size // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_data = [p.data[i, x - (p.patch_size // 2): x + (p.patch_size // 2), y - (p.patch_size // 2): y + (p.patch_size // 2)] for i in range(p.nb_layers)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4,5,7,5,8,4,7,3,67,3,2,8,3,5,7,2,6,5,6])\n",
    "x[3:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "4511-4447"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, key in enumerate(model_setup.keys()):\n",
    "    model_setup[key]['input_shape'] = train_data[0][0][i].shape\n",
    "    if multires:\n",
    "        assert embed_shape is not None\n",
    "        model_setup[key]['output_shape'] = embed_shape\n",
    "    else:\n",
    "        model_setup[key]['output_shape'] = train_data.n_species\n",
    "print([[m['input_shape'], m['output_shape']] for m in model_setup.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = PatchesDatasetCooccurrences(\n",
    "    occurrences=val_occ_path,\n",
    "    providers=providers, \n",
    "    species=train_data.species, \n",
    "    n_low_occ=n_max_low_occ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=batch_size)#, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = [make_model(model_dict) for model_dict in model_setup.values()]\n",
    "if multires:\n",
    "    model = MultiScaleModel(\n",
    "        model_list[0], model_list[1], train_data.n_species, embed_shape, embed_shape\n",
    "    ).to(dev)\n",
    "else:\n",
    "    model = model_list[0].to(dev)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# loss functions\n",
    "loss_fn = eval(loss)\n",
    "species_weights = torch.tensor(train_data.species_weights).to(dev)\n",
    "val_loss_fn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch ='resnet18'\n",
    "block = BasicBlock\n",
    "layers = [2, 2, 2, 2]\n",
    "pretrained = False# 'ResNet18_Weights.IMAGENET1K_V1' \n",
    "progress = True\n",
    "\n",
    "model = ResNet(block, layers, **kwargs)\n",
    "    # if pretrained:\n",
    "    #     state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "    #                                           progress=progress)\n",
    "    #     model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for po_inputs, bg_inputs, labels in tqdm(train_loader):\n",
    "    labels = labels.to(torch.float32).to(dev) \n",
    "    print(labels.shape)\n",
    "\n",
    "    if multires:\n",
    "        inputsA = po_inputs[0].to(torch.float32).to(dev)\n",
    "        inputsB = po_inputs[1].to(torch.float32).to(dev)\n",
    "        y_pred = torch.sigmoid(model(inputsA, inputsB))\n",
    "\n",
    "    else:\n",
    "        if random_bg_path is None:\n",
    "            inputs = po_inputs[0].to(torch.float32).to(dev)\n",
    "            print(po_inputs[0].shape)\n",
    "        else:\n",
    "            inputs = torch.cat((po_inputs[0], bg_inputs[0]), 0).to(torch.float32).to(dev)\n",
    "            print(po_inputs[0].shape, len(po_inputs))\n",
    "            print(len(bg_inputs), bg_inputs[0].shape)\n",
    "            print(inputs.shape)\n",
    "        y_pred = torch.sigmoid(model(inputs))\n",
    "            \n",
    "    if random_bg_path is None:\n",
    "       train_loss = loss_fn(y_pred, labels, species_weights)\n",
    "          \n",
    "    else:\n",
    "        po_pred = y_pred[0:len(po_inputs[0])]\n",
    "        bg_pred = y_pred[len(po_inputs[0]):]        \n",
    "        train_loss = loss_fn(po_pred, labels, species_weights, lambda2, bg_pred)\n",
    "\n",
    "    print(train_loss)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sigmoid(model_list[0](inputsA)).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sigmoid(model_list[1](inputsB)).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "po_inputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "model = get_model(model, input_shape[0], n_species, model_params, patch_size).to(dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = [True if model == 'MLP' else False for model in models]\n",
    "flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = []\n",
    "for group, patch_size, f in zip(covariates, patch_sizes, flatten):\n",
    "\n",
    "    group_providers = []\n",
    "    for cov in group:\n",
    "        print(f\"\\t - {cov}\")\n",
    "        if 'SatelliteImages' in cov:\n",
    "            if f and patch_size != 1: \n",
    "                exit(\"jpeg patch provider for satellite images cannot flatten image patches\")\n",
    "            group_providers.append(JpegPatchProvider(cov, size=patch_size))\n",
    "        elif '.tif' in cov:\n",
    "            group_providers.append(RasterPatchProvider(cov, size=patch_size, flatten=f))\n",
    "        else:\n",
    "            group_providers.append(MultipleRasterPatchProvider(cov, size=patch_size, flatten=f))\n",
    "\n",
    "    providers.append(group_providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MultiScalePatchesDatasetCooccurrences(occurrences=train_occ_path, providersA=providers[0], providersB=providers[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "item = train_data.items.iloc[index][train_data.item_columns].to_dict()\n",
    "item_species = train_data.items.iloc[index][train_data.label_name]\n",
    "labels = 1 * np.isin(train_data.species, item_species)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shapes = [input.shape for input in train_data[0][0]]\n",
    "n_species = train_data.n_species\n",
    "print(f\"input shape = {input_shapes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_max_low_occ = 50\n",
    "low_occ_species = train_data.species_counts[train_data.species_counts <= n_max_low_occ].index\n",
    "low_occ_species_idx = np.where(np.isin(train_data.species, low_occ_species))[0]\n",
    "print(f\"nb of species with less than {n_max_low_occ} occurrences = {len(low_occ_species_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data = MultiScalePatchesDatasetCooccurrences(occurrences=val_occ_path, providers=providers, species=train_data.species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelA = MLP(input_shapes[0][0], 512, 5, 1000)\n",
    "modelB = get_resnet(512)\n",
    "model = MultiScaleModel(modelA, modelB, 512, 512, n_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "loss_fn = eval(loss)\n",
    "species_weights = torch.tensor(train_data.species_weights)\n",
    "val_loss_fn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(inputsA, inputsB), labels = batch\n",
    "print(inputsA.shape, inputsB.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputsA = inputsA.to(torch.float32)\n",
    "inputsB = inputsB.to(torch.float32)\n",
    "out = model(inputsA, inputsB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = torch.sigmoid(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1e-28 + 1e-05 * np.abs(p.nodata_value[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.where(np.isclose(p.data, p.nodata_value[0], atol=1e-8), np.nan, p.data)[0,3500:4000,3000:4000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_soil.rasters_providers[0].nodata_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in p_bioclim.rasters_providers[1:]:\n",
    "    pseudoabsence_locations += np.where(p.data != 0, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.where(pseudoabsence_locations != 0, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5467*8143"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in p_bioclim.rasters_providers:\n",
    "    print(f\"{p.name}: xmin={p.x_min} / ymin={p.y_min} / nrows={p.n_rows} / ncold={p.n_cols} / nlayers={p.nb_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in p_soil.rasters_providers:\n",
    "    print(f\"{p.name}: xmin={p.x_min} / ymin={p.y_min} / nrows={p.n_rows} / ncold={p.n_cols} / nlayers={p.nb_layers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# patch_size = 1\n",
    "# flatten = True \n",
    "# p_bioclim = MultipleRasterPatchProvider(bioclim_dir, size=patch_size, flatten=flatten) \n",
    "# p_soil = MultipleRasterPatchProvider(soil_dir, size=patch_size, flatten=flatten) \n",
    "# p_landcover = RasterPatchProvider(landcover_dir, size=patch_size, flatten=flatten)\n",
    "p_sat = JpegPatchProvider(sat_dir, size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = PatchesDatasetCooccurrences(occurrences=po_path, providers=(p_sat))\n",
    "print(f\"\\nTRAINING DATA: n_items={len(train_data)}, n_species={len(train_data.species)}\")\n",
    "print(train_data[0][0].shape, train_data[0][1].shape)\n",
    "\n",
    "n_features = train_data[0][0].shape[0]\n",
    "n_species = len(train_data.species)\n",
    "print(f\"nb of features = {n_features}\")\n",
    "\n",
    "val_data = PatchesDatasetCooccurrences(occurrences=pa_path, providers=(p_sat), species=train_data.species)\n",
    "print(f\"\\nVALIDATION DATA: n_items={len(val_data)}, n_species={len(val_data.species)}\")\n",
    "print(val_data[0][0].shape, val_data[0][1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_occ_species = train_data.species_counts[train_data.species_counts < 50].index\n",
    "low_occ_species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_occ_species_idx = np.where(np.isin(train_data.species, low_occ_species))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_occ_species_idx[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=1024)\n",
    "labels_list = []\n",
    "for inputs, labels in tqdm(val_loader):\n",
    "    labels_list.append(labels.numpy())\n",
    "labels = np.concatenate(labels_list)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[:, low_occ_species_idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.rand(labels.shape).numpy()\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_score(labels[:, low_occ_species_idx], pred[:, low_occ_species_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ".shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1')\n",
    "weights = model.conv1.weight.data.clone()\n",
    "model.conv1 = torch.nn.Conv2d(6, 64, kernel_size=(7,7), stride=(2,2),\n",
    "                              padding=(3,3), bias=False)\n",
    "# first three bands are RGB\n",
    "model.conv1.weight.data[:, :3, :, :] = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1.weight.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conv1.weight.data[:, 3:, :, :].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[:,0,:,:].repeat((3,1,1,1)).reshape((64,3,7,7))[0,:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights[0,0,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(weights='ResNet18_Weights.IMAGENET1K_V1')\n",
    "weights = model.conv1.weight.data.clone()\n",
    "model.conv1 = torch.nn.Conv2d(len(p_sat.bands_names), 64, kernel_size=(7,7), stride=(2,2),\n",
    "                              padding=(3,3), bias=False)\n",
    "# first three bands are RGB\n",
    "model.conv1.weight.data[:, :3, :, :] = weights\n",
    "# initialize weights for 4th band (NIR) to pretrained weights for R\n",
    "model.conv1.weight.data[:,-1,:,:] = weights[:,0,:,:]\n",
    "model.fc = torch.nn.Linear(512, n_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=100)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "loss_fn = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, labels in train_loader:\n",
    "    print('-----------------------')\n",
    "    inputs = inputs.to(torch.float32)\n",
    "    labels = labels.to(torch.float32)\n",
    "\n",
    "    print(inputs.size())\n",
    "    print(labels.size())\n",
    "    pred = model(inputs)\n",
    "    print(pred.size())\n",
    "    pred_sigmoid = torch.sigmoid(pred)\n",
    "    loss = loss_fn(pred_sigmoid, labels)\n",
    "    print(loss)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = (img - p_sat.stats[folder]['mean']) / p_sat.stats[folder]['std']\n",
    "img[0:4,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(122-77.3)/25.6\n",
    "# [[140, 134, 122],\n",
    "# [130, 124, 110],\n",
    "# [126, 118, 105],\n",
    "# [131, 123, 110]]]\n",
    "\n",
    "# {'rgb': {'mean': array([85.53290863, 89.00972544, 77.32355934]),\n",
    "#   'std': array([28.46643494, 25.3613768 , 25.57295764])},"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "        tensor_list = []\n",
    "        for folder in set([self.channel_folder[x] for x in self.channels]):\n",
    "            path = os.path.join(self.root_path, folder, sub_folder_1, sub_folder_2, patch_id+self.ext)\n",
    "            img = np.asarray(Image.open(path))\n",
    "            if self.normalize:\n",
    "                img = (img - self.stats[folder]['mean']) / self.stats[folder]['std']\n",
    "            if folder == 'rgb':\n",
    "                img = img.transpose((2,0,1))\n",
    "            else:\n",
    "                img = np.expand_dims(img, axis=0)\n",
    "            tensor_list.append(img)\n",
    "\n",
    "        tensor = np.concatenate(tensor_list)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers=5\n",
    "width=1000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "checkpoint = torch.load(f\"models/0129_MLP_env_1x1_an_slds/last.pth\") \n",
    "model = MLP(n_features, n_species, n_layers, width).to(dev)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "val_loader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "for inputs, labels in tqdm(val_loader):\n",
    "\n",
    "    inputs = inputs.to(torch.float32).to(dev)\n",
    "    labels = labels.to(torch.float32).to(dev) \n",
    "\n",
    "    y_pred = model(inputs)\n",
    "    y_pred_sigmoid = torch.sigmoid(y_pred)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import full_weighted_loss, log_loss, an_slds_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_loss = ((log_loss(y_pred_sigmoid) * labels) + (log_loss(1 - y_pred_sigmoid) * (1 - labels))).sum(axis=1)\n",
    "site_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_weight = 1 / (labels.sum(axis=1) + 1e-5)\n",
    "site_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(site_loss * site_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((log_loss(y_pred_sigmoid) * labels) + (log_loss(1 - y_pred_sigmoid) * (1 - labels))).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.transpose((1/labels.sum(axis=1)).repeat((970,1)), 0, 1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_sigmoid = torch.sigmoid(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((log_loss(y_pred_sigmoid) * labels) + (log_loss(1 - y_pred_sigmoid) * (1 - labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_site_loss = ((log_loss(y_pred_sigmoid) * labels) + (log_loss(1 - y_pred_sigmoid) * (1 - labels))) * torch.transpose((1/labels.sum(axis=1)).repeat((970,1)), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((log_loss(y_pred_sigmoid) * labels) + (log_loss(1 - y_pred_sigmoid) * (1 - labels))).sum(axis=1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(1/labels.sum(axis=1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "site_loss = ((log_loss(y_pred_sigmoid) * labels) + (log_loss(1 - y_pred_sigmoid) * (1 - labels))).sum(axis=1)\n",
    "site_weight = (1/labels.sum(axis=1))\n",
    "print(site_loss.size(), site_weight.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(site_loss * site_weight).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_site_loss.sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_weights = torch.tensor(train_data.species_weights)\n",
    "species_weights.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(log_loss(pred) * labels).shape# * species_weights.repeat((batch_size, 1))).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred * labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.ones(labels.shape[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_weights = torch.tensor(train_data.species_weights.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_weights.repeat((100,1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(species_weights/(species_weights-1)).repeat((batch_size,1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0 \n",
    "item_columns=['lat','lon','patchID','dayOfYear']\n",
    "train_data.items.iloc[index][item_columns].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.items.iloc[index]['speciesId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, labels in tqdm(train_loader):\n",
    "    print(inputs.shape, labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:,0:2,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((img - stats[folder]['mean']) / stats[folder]['std'])[:,0:2,0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape = np.array(Image.open(files[0], mode='r')).shape \n",
    "dims = len(img_shape)\n",
    "dims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = np.array([0.0] * img_shape[2]) if dims == 3 else np.array([0.0])\n",
    "n_terms = 0\n",
    "\n",
    "for f in files:\n",
    "    img = np.array(Image.open(f, mode='r'))\n",
    "    nans = np.sum(np.isnan(img))\n",
    "    if nans != 0: \n",
    "        print(f)\n",
    "        break\n",
    "    img_sum = np.sum(img, axis=(0,1))\n",
    "    sums += img_sum\n",
    "    n_terms += img.shape[0] * img.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = sums / n_terms\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'mean': means}).to_csv('data/sample_data/SatelliteImages/rgb_means.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = pd.read_csv('data/sample_data/SatelliteImages/rgb_means.csv')\n",
    "means = np.array(means['mean'])\n",
    "means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = np.array([0.0] * img_shape[2]) if dims == 3 else np.array([0.0])\n",
    "n_terms = 0\n",
    "\n",
    "for f in files:\n",
    "    img = np.array(Image.open(f, mode='r'))\n",
    "    sum_dev_mean = np.sum(np.power(img - means, 2), axis=(0,1))\n",
    "    sums += sum_dev_mean\n",
    "    n_terms += img.shape[0] * img.shape[1]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_devs = np.power(sums / n_terms, 0.5)\n",
    "std_devs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'std_dev': std_devs}).to_csv('data/sample_data/SatelliteImages/rgb_std_devs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = 'data/full_data/'\n",
    "bioclim_dir = datadir+'EnvironmentalRasters/Climate/BioClimatic_Average_1981-2010/'\n",
    "soil_dir = datadir+'EnvironmentalRasters/Soilgrids/'\n",
    "po_path = datadir+'Presence_only_occurrences/Presences_only_train_sampled_10_percent_min_100_occurrences.csv' #Presences_only_train_sampled_25_percent_min_10_occurrences.csv'\n",
    "pa_path = datadir+'Presence_Absence_surveys/Presences_Absences_train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences=po_path\n",
    "label_name='speciesId'\n",
    "item_columns=['lat','lon','patchID','dayOfYear']\n",
    "df = pd.read_csv(occurrences, sep=\";\", header='infer', low_memory=False)\n",
    "items = pd.DataFrame(df.groupby(item_columns)[label_name].agg(list)).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = sat_dir\n",
    "ext = '.jpeg'\n",
    "sub_dirs = next(os.walk(root_path))[1]\n",
    "select = [x for x in ['rgb','nir'] if x in sub_dirs]\n",
    "channels = ['red','green','blue'] + [x for x in select if x != 'rgb']\n",
    "channel_folder = {'red': 'rgb', 'green': 'rgb', 'blue': 'rgb','nir':'nir'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = items.iloc[0][item_columns].to_dict()\n",
    "patch_id = str(int(item['patchID']))\n",
    "sub_folder_1 = patch_id[-2:]\n",
    "sub_folder_2 = patch_id[-4:-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for folder in set([channel_folder[x] for x in channels]):\n",
    "    path = os.path.join(root_path, folder, sub_folder_1, sub_folder_2, patch_id+ext)\n",
    "    print(folder, path)\n",
    "    \n",
    "    img = np.asarray(Image.open(path))\n",
    "    if folder == 'rgb':\n",
    "        img = img.transpose((2,0,1))\n",
    "    else:\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    stats_path = os.path.join(root_path, folder+'_stats.csv')\n",
    "    print(stats_path)\n",
    "    stats = pd.read_csv(stats_path, sep=';', index_col=0)\n",
    "    #mean, std = df.loc[0, 'mean'], df.loc[0, 'std']\n",
    "                #     img = (img-mean)/std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[:,0:3,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(img.shape[0]):\n",
    "    img[i,:,:] = img[i,:,:] - stats.loc[i,'mean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = pd.DataFrame({\n",
    "    'mean': np.nanmean(imgs,axis=(0,2,3)),\n",
    "    'std': np.nanstd(imgs,axis=(0,2,3))\n",
    "})\n",
    "stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_imgs = imgs.reshape(3,100,128,128)\n",
    "re_imgs[:, 0, 0:3, 0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = MultiScalePatchesDatasetCooccurrences(\n",
    "    occurrences=po_path, \n",
    "    providers=((p_bioclim, p_soil))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "providers = (p_bioclim, p_soil, p_sat)\n",
    "patch_sizes = [p.patch_size for p in providers]\n",
    "patch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_patch_sizes = list(set(patch_sizes))\n",
    "providers_grouped = []\n",
    "for patch_size in unique_patch_sizes:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[0][0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.n_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inputs, labels in tqdm(train_loader):\n",
    "    inputs = inputs#.to(torch.float32)\n",
    "    labels = labels#.to(torch.float32)\n",
    "    break\n",
    "\n",
    "    env = inputs[0].to(torch.float32)\n",
    "    sat = inputs[1].to(torch.float32)\n",
    "\n",
    "    print(len(inputs))\n",
    "    print(labels.shape)\n",
    "\n",
    "    env_vars = inputs[0]\n",
    "    sat_vars = inputs[1]\n",
    "    print(env_vars.shape, sat_vars.shape)\n",
    "\n",
    "    break\n",
    "#1m32s for ((p_bioclim, p_soil), (p_sat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = inputs[0].to(torch.float32)\n",
    "sat = inputs[1].to(torch.float32)\n",
    "print(env.shape, sat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_img = train_data[0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = train_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occurrences=po_path\n",
    "label_name='speciesId'\n",
    "item_columns=['lat','lon','patchID','dayOfYear']\n",
    "df = pd.read_csv(occurrences, sep=\";\", header='infer', low_memory=False)\n",
    "species = np.unique(df[label_name].values)\n",
    "items = pd.DataFrame(df.groupby(item_columns)[label_name].agg(list)).reset_index()\n",
    "providers = ((p_bioclim, p_soil), (p_sat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_sizes = []\n",
    "one_provider_in_group = []\n",
    "for provider in providers:\n",
    "    try:\n",
    "        patch_sizes.append(provider.patch_size)\n",
    "        one_provider_in_group.append(True)\n",
    "    except:\n",
    "        group_patch_sizes = [p.patch_size for p in provider]\n",
    "        print('group', group_patch_sizes)\n",
    "        assert len(set(group_patch_sizes)) == 1\n",
    "        patch_sizes.append(group_patch_sizes[0])\n",
    "        one_provider_in_group.append(False)\n",
    "print(patch_sizes)\n",
    "print(one_provider_in_group)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_list = [MetaPatchProvider(p, one_provider=one_p) for p, one_p in zip(providers, one_provider_in_group)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get item\n",
    "item = items.iloc[0][item_columns].to_dict()\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches = []\n",
    "for p in provider_list:\n",
    "    patch = p[item]\n",
    "    print(patch.shape)\n",
    "    patches.append(patch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = patches[0]\n",
    "rgb = patches[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pro in p:\n",
    "    print(str(pro))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetaPatchProvider(p_sat, one_provider=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetaPatchProvider(providers[1], one_provider=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MetaPatchProvider(providers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provider_patch_sizes = [p.patch_size for p in providers]\n",
    "provider_patch_sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_patch_sizes = list(set(provider_patch_sizes))\n",
    "num_patch_sizes = len(unique_patch_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in unique_patch_sizes:\n",
    "    idx = list(np.where(np.array(provider_patch_sizes) == p)[0])\n",
    "    print('--------------------------------------------')\n",
    "    print(p, idx)\n",
    "    one_provider = True if len(idx)==1 else False\n",
    "    meta_p = MetaPatchProvider((providers[i] for i in idx), one_provider)\n",
    "    print(meta_p)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = sat_dir\n",
    "sub_dirs = next(os.walk(root_path))[1]\n",
    "sub_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "train_data = PatchesDataset(occurrences=po_path, providers=(p_bioclim, p_soil, p_sat))\n",
    "occurrences=po_path\n",
    "#providers=(p_bioclim, p_soil)\n",
    "label_name='speciesId'\n",
    "item_columns=['lat','lon','patchID','dayOfYear']\n",
    "df = pd.read_csv(occurrences, sep=\";\", header='infer', low_memory=False)\n",
    "species = np.unique(df[label_name].values)\n",
    "items = df[item_columns + [label_name]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "item = items.iloc[index][item_columns].to_dict()\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_id = str(int(item['patchID']))\n",
    "sub_folder_1 = patch_id[-2:]\n",
    "sub_folder_2 = patch_id[-4:-2]\n",
    "ext = '.jpeg'\n",
    "patch_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = 'data/sample_data/SatelliteImages/'\n",
    "channel_folder = {'red': 'rgb', 'green': 'rgb', 'blue': 'rgb','nir':'nir'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'rgb'\n",
    "path = os.path.join(root_path, folder, sub_folder_1, sub_folder_2, patch_id+ext)\n",
    "img = np.asarray(Image.open(path)) \n",
    "img = img.transpose((2,0,1))\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img[0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_tensor = {'order': [], 'tensors':[]}\n",
    "for channel, channel_filename in channels_dict.items():\n",
    "    print(channel)\n",
    "    if channel not in list_tensor['order']:\n",
    "        path = os.path.join(root_path, channel_filename, sub_folder_1, sub_folder_2, patch_id+ext)\n",
    "        print(path)\n",
    "        img = np.asarray(Image.open(path))\n",
    "        print(img.shape)\n",
    "        if channel in ['red','green','blue']:\n",
    "            img = img.transpose((2,0,1))\n",
    "            print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_id = str(int(item['patchID']))\n",
    "rgb_path = f\"{self.rgbnir_dir}rgb/{patch_id[-2:]}/{patch_id[-4:-2]}/{patch_id}.jpeg\"\n",
    "rgb_img = (np.asarray(Image.open(rgb_path)) / 255.0).transpose((2,0,1))\n",
    "\n",
    "nir_path = f\"{self.rgbnir_dir}nir/{patch_id[-2:]}/{patch_id[-4:-2]}/{patch_id}.jpeg\"\n",
    "nir_img = np.expand_dims(np.asarray(Image.open(nir_path)) / 255.0, axis=0)\n",
    "\n",
    "rgbnir = np.concatenate([rgb_img, nir_img])\n",
    "if self.rgbnir_patch_size != 128:\n",
    "    rgbnir = rgbnir[:, round((rgbnir[0].shape[0] - self.rgbnir_patch_size) /2):round((rgbnir[0].shape[0] + self.rgbnir_patch_size) /2),\n",
    "                                    round((rgbnir[0].shape[1] - self.rgbnir_patch_size) /2):round((rgbnir[0].shape[1] + self.rgbnir_patch_size) /2)]\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class JpegPatchProvider(PatchProvider)\n",
    "# init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data.species), train_data.species[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name='speciesId'\n",
    "item_columns=['lat','lon','patchID','dayOfYear']\n",
    "df = pd.read_csv(po_path, sep=\";\", header='infer', low_memory=False)\n",
    "species = train_data.species\n",
    "items = df[item_columns + [label_name]]\n",
    "items.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items2 = pd.DataFrame(df.groupby(item_columns)[label_name].agg(list)).reset_index()\n",
    "items2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df.groupby(item_columns)[label_name].count()\n",
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts[counts > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for index in range(items2.shape[0]):\n",
    "    item = items2.iloc[index][item_columns].to_dict()\n",
    "    item_sps = items2.iloc[index][label_name]\n",
    "    labels = 1 * np.isin(species, item_sps)\n",
    "    if np.sum(labels) == 0:\n",
    "        print('!!!!!!!!', index)\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "item = items2.iloc[index][item_columns].to_dict()\n",
    "item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_sps = items2.iloc[index][label_name]\n",
    "print(len(item_sps), item_sps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = 1 * np.isin(species, item_sps)\n",
    "labels_f = 1 * np.isin(species, item_sps_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(labels == labels_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.sum(labels), np.sum(labels_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items[~items['speciesId'].isin(species)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 447\n",
    "item = items.iloc[index][item_columns].to_dict()\n",
    "item_species = items.query(\n",
    "    ' and '.join([f'{k} == {v}' for k, v in item.items()])\n",
    ")[label_name].values\n",
    "labels = 1 * np.isin(species, item_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(s, s in species) for s in item_species]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{np.sum([s in species for s in item_species])}/{len(item_species)}\")\n",
    "print(np.sum(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Making dataset for presence-only training data...\")\n",
    "train_data = PatchesDataset(occurrences=po_path, providers=(p_bioclim, p_soil))\n",
    "print(f\"\\nTRAINING DATA: n_items={len(train_data)}, n_species={len(train_data.species)}\")\n",
    "\n",
    "n_features = train_data[0][0].shape[0]\n",
    "n_species = len(train_data.species)\n",
    "print(f\"nb of features = {n_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"Making dataset for presence-absence validation data...\")\n",
    "val_data = PatchesDataset(occurrences=pa_path, providers=(p_bioclim, p_soil), species=train_data.species)\n",
    "print(f\"\\nVALIDATION DATA: n_items={len(val_data)}, n_species={len(val_data.species)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data loaders\n",
    "batch_size = 1024\n",
    "# train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size, num_workers=16)\n",
    "val_loader = torch.utils.data.DataLoader(val_data, shuffle=False, batch_size=batch_size, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_name = '0116_MLP_env_2x2_flat_train_tinyPO'\n",
    "checkpoint = torch.load(f\"models/{run_name}/best_val_loss.pth\")\n",
    "checkpoint['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_layers = 5\n",
    "width = 1000\n",
    "learning_rate = 1e-3\n",
    "\n",
    "model = MLP(n_features, n_species, n_layers, width)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "val_loss_list, labels_list, y_pred_list = [], [], []\n",
    "\n",
    "for inputs, labels in tqdm(val_loader):\n",
    "    inputs = inputs.to(torch.float32)\n",
    "    labels = labels.to(torch.float32)\n",
    "    labels_list.append(labels.cpu().detach().numpy())\n",
    "\n",
    "    y_pred = model(inputs)\n",
    "    y_pred_sigmoid = torch.sigmoid(y_pred)\n",
    "    y_pred_list.append(y_pred_sigmoid.cpu().detach().numpy())\n",
    "\n",
    "    val_loss = loss_fn(y_pred, labels)\n",
    "    val_loss_list.append(val_loss.cpu().detach())    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.concatenate(labels_list)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = np.concatenate(y_pred_list)\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(labels, y_pred)\n",
    "\n",
    "# patch size = 1            AUC = 0.5725362624834227\n",
    "# patch size = 2 (flat)     AUC = 0.46973261663879734"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glc23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
