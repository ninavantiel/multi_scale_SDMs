{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import wandb\n",
    "\n",
    "from GLC23PatchesProviders import MultipleRasterPatchProvider, RasterPatchProvider, JpegPatchProvider\n",
    "from GLC23Datasets import PatchesDataset, PatchesDatasetMultiLabel\n",
    "from models import cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAMPLE DATA\n",
    "data_path = 'data/sample_data/' # root path of the data\n",
    "presence_only_path = data_path+'Presence_only_occurrences/Presences_only_train_sample.csv'\n",
    "presence_absence_path = data_path+'Presence_Absences_occurrences/Presences_Absences_train_sample.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVARIATES\n",
    "p_bioclim = MultipleRasterPatchProvider(\n",
    "    data_path+'EnvironmentalRasters/Climate/BioClimatic_Average_1981-2010/'\n",
    ") #19\n",
    "p_hfp_d = MultipleRasterPatchProvider(data_path+'EnvironmentalRasters/HumanFootprint/detailed/') #14\n",
    "p_hfp_s = RasterPatchProvider(data_path+'EnvironmentalRasters/HumanFootprint/summarized/HFP2009_WGS84.tif') #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING DATA: n=100\n",
      "in_shape = torch.Size([6, 128, 128])\n",
      "out_shape = torch.Size([96])\n",
      "Number of covariates = 6\n",
      "Number of species = 96\n"
     ]
    }
   ],
   "source": [
    "# TRAINING DATA: presence only\n",
    "presence_only = PatchesDatasetMultiLabel(\n",
    "    occurrences=presence_only_path, \n",
    "    providers=(p_bioclim, p_hfp_d, p_hfp_s), \n",
    "    device=dev\n",
    ")\n",
    "print(f\"\\nTRAINING DATA: n={len(presence_only)}\\nin_shape = {presence_only[0][0].cpu().detach().shape}\\nout_shape = {presence_only[0][1].cpu().detach().shape}\")\n",
    "\n",
    "n_features = presence_only[0][0].cpu().detach().shape[0]\n",
    "n_species = len(presence_only.unique_sorted_targets)\n",
    "print(f\"Number of covariates = {n_features}\")\n",
    "print(f\"Number of species = {n_species}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VALIDATION: n=100\n",
      "in_shape=torch.Size([6, 128, 128])\n",
      "out_shape=torch.Size([96]), n_species=96\n"
     ]
    }
   ],
   "source": [
    "# VALIDATION DATA: presence absence\n",
    "presence_absence = PatchesDatasetMultiLabel(\n",
    "    occurrences=presence_absence_path, \n",
    "    providers=(p_bioclim, p_hfp_d, p_hfp_s),\n",
    "    ref_targets=presence_only.unique_sorted_targets,\n",
    "    device=dev\n",
    ")\n",
    "print(f\"VALIDATION: n={len(presence_absence)}\\nin_shape={presence_absence[0][0].cpu().detach().shape}\\nout_shape={presence_absence[0][1].cpu().detach().shape}, n_species={len(presence_absence.unique_sorted_targets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(presence_only, shuffle=True, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(presence_absence, shuffle=True, batch_size=len(presence_absence))\n",
    "model = cnn(n_features, n_species).to(dev)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:01<00:00,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOSS:  tensor(0.7216, dtype=torch.float64)\n",
      "(100, 96) (100, 96)\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mprint\u001b[39m(y_pred\u001b[39m.\u001b[39mshape, labels\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     26\u001b[0m \u001b[39mprint\u001b[39m(labels)\n\u001b[0;32m---> 27\u001b[0m auc_rocs \u001b[39m=\u001b[39m roc_auc_score(labels, y_pred, average\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m     28\u001b[0m avg_auc \u001b[39m=\u001b[39m auc_rocs\u001b[39m.\u001b[39mmean()\n\u001b[1;32m     29\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m) AVG_AUC=\u001b[39m\u001b[39m{\u001b[39;00mavg_auc\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/glc23/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:580\u001b[0m, in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    572\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    573\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39mmax_fpr),\n\u001b[1;32m    574\u001b[0m         y_true,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    577\u001b[0m         sample_weight\u001b[39m=\u001b[39msample_weight,\n\u001b[1;32m    578\u001b[0m     )\n\u001b[1;32m    579\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# multilabel-indicator\u001b[39;00m\n\u001b[0;32m--> 580\u001b[0m     \u001b[39mreturn\u001b[39;00m _average_binary_score(\n\u001b[1;32m    581\u001b[0m         partial(_binary_roc_auc_score, max_fpr\u001b[39m=\u001b[39;49mmax_fpr),\n\u001b[1;32m    582\u001b[0m         y_true,\n\u001b[1;32m    583\u001b[0m         y_score,\n\u001b[1;32m    584\u001b[0m         average,\n\u001b[1;32m    585\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    586\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/glc23/lib/python3.9/site-packages/sklearn/metrics/_base.py:118\u001b[0m, in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m    116\u001b[0m     y_true_c \u001b[39m=\u001b[39m y_true\u001b[39m.\u001b[39mtake([c], axis\u001b[39m=\u001b[39mnot_average_axis)\u001b[39m.\u001b[39mravel()\n\u001b[1;32m    117\u001b[0m     y_score_c \u001b[39m=\u001b[39m y_score\u001b[39m.\u001b[39mtake([c], axis\u001b[39m=\u001b[39mnot_average_axis)\u001b[39m.\u001b[39mravel()\n\u001b[0;32m--> 118\u001b[0m     score[c] \u001b[39m=\u001b[39m binary_metric(y_true_c, y_score_c, sample_weight\u001b[39m=\u001b[39;49mscore_weight)\n\u001b[1;32m    120\u001b[0m \u001b[39m# Average the results\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[39mif\u001b[39;00m average \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/glc23/lib/python3.9/site-packages/sklearn/metrics/_ranking.py:339\u001b[0m, in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[39m\"\"\"Binary roc auc score.\"\"\"\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_true)) \u001b[39m!=\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[0;32m--> 339\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    340\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOnly one class present in y_true. ROC AUC score \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    341\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mis not defined in that case.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    342\u001b[0m     )\n\u001b[1;32m    344\u001b[0m fpr, tpr, _ \u001b[39m=\u001b[39m roc_curve(y_true, y_score, sample_weight\u001b[39m=\u001b[39msample_weight)\n\u001b[1;32m    345\u001b[0m \u001b[39mif\u001b[39;00m max_fpr \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m max_fpr \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    print(f\"EPOCH {epoch}\")\n",
    "\n",
    "    model.train()\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        # forward pass\n",
    "        y_pred = model(inputs)\n",
    "        #print(inputs.shape, labels.shape, y_pred.shape)\n",
    "        loss = loss_fn(y_pred, labels)\n",
    "\n",
    "        # backward pass and weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(\"LOSS: \", loss.cpu().detach())\n",
    "\n",
    "    model.eval()\n",
    "    for inputs, labels in test_loader:\n",
    "        y_pred = model(inputs)\n",
    "        val_loss = loss_fn(y_pred, labels)\n",
    "\n",
    "        y_pred = y_pred.cpu().detach().numpy()\n",
    "        labels = labels.cpu().detach().numpy()\n",
    "        print(y_pred.shape, labels.shape)\n",
    "        print(labels)\n",
    "        auc_rocs = roc_auc_score(labels, y_pred, average=None)\n",
    "        avg_auc = auc_rocs.mean()\n",
    "        print(f\"{epoch}) AVG_AUC={avg_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 96)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  3,  9, 38, 41, 46, 57, 61, 83, 93])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = np.where(labels.sum(axis=0) != 0)[0]\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels.sum(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[:,idx].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 96)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[idx,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.where(labels.sum(axis=0) != 0)[0]\n",
    "idx\n",
    "auc_rocs = roc_auc_score(labels[:,idx], y_pred[:,idx], average=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.44444444, 0.47979798, 0.51530612, 0.41414141, 0.18181818,\n",
       "       0.98989899, 0.65656566, 0.06565657, 0.40306122, 0.47979798])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_rocs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "glc23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
